# Synthetic ECG Data Generation


## Data Generation

### Model
#### GAN
Several GAN architectures were tried, the best performing (in terms of subjective human judgement) is detailed below. The GAN generates 10 second ECG records, which can then be added together in order to generate longer ECG signals as needed.

##### Discriminator

The Discriminator is a CNN designed to classify input signals as real (actual ECG data) or fake (generated by the Generator). Its architecture is as follows:

- Input Layer: Accepts one-dimensional ECG data of shape (1000, 1).
- Convolutional Layers:
    - First layer: Conv1D with 128 filters, kernel size of 5, stride of 2, padding 'same', and Leaky ReLU activation.
    - Second layer: Another Conv1D layer with 256 filters, similar specifications, and Leaky ReLU activation.
    - Max Pooling Layers: Follow each convolutional layer to reduce dimensionality, each with a pool size of 2.
- Dropout Layers: Included after each max pooling with a dropout rate of 0.3 to prevent overfitting.
- Flatten Layer: To convert the multi-dimensional output into a one-dimensional array.
- Output Layer: A dense layer with a single neuron and a sigmoid activation function to output a probability indicating whether the input is real or fake.

##### Generator
The Generator synthesizes ECG signals from a random noise input. Its architecture includes:
- Input Layer: Takes a noise vector of dimension (100,).
- Dense and Reshape Layers: First, a dense layer with 512 units and Leaky ReLU activation, followed by Batch Normalization. Then, reshaping the output to (8, 64).
- LSTM Layers:
- Two LSTM layers, each with 64 units, return sequences enabled, and followed by Batch Normalization.
- TimeDistributed Dense Layer: Applies a dense operation to every temporal slice of the input, with 125 units and tanh activation.
- Output Reshaping: The final output is reshaped to (1000, 1), representing the generated ECG signal.

##### Input/Output Specifications
- Discriminator Input: Real or fake ECG signals of shape (1000, 1).
- Generator Input: Random noise vectors of shape (100,).
- Discriminator Output: A probability score (0 to 1) indicating the likelihood of the input being a real ECG signal.
- Generator Output: Synthetic ECG signals of shape (1000, 1).

##### Training

The GAN is trained through a competitive process where the Generator and Discriminator are simultaneously updated:

1. Fake Signal Generation: The Generator creates ECG signals from random noise.
2. Combining Real and Fake Signals: These are mixed with actual ECG signals.
3. Discriminator Training: The Discriminator is trained to distinguish real signals from fake ones. The loss is calculated based on its ability to correctly classify these signals.
4. Generator Training: The Generator is updated based on the Discriminator's performance, with the aim to improve its ability to generate realistic ECG signals that can fool the Discriminator.
5. Repeat: The training process is iterative, with both networks improving over time through adversarial training.

##### Evaluation
While there are observable differences between the ECG signals generated from different models, the variation of generated sequences from a single model is negligible. This is due to mode collapse, a common problem with GANs. On one hand, this is not unrealistic, as the ECG signals from a single patient typically ressemble one another quite closely, whereas signals recorded from different patients are usually quite distinct. However, the signals generated from this GAN are too regular: There is almost no heart rate variation.

A positive feature of the generated sequences is that some of them contain noise/artifact, as do real ECG signals, which adds some realism to the generated signals. 

#### VAE

## Web App

### Frontend
The simple frontend is implemented in React. It features a form with three input fields: a time input for "Length of Recording" formatted as minutes and seconds, a dropdown selection for "Type" of recording, and a numerical input for "BPM" (beats per minute). There are also two buttons: one to "Generate" the recording and another to "Download File", which appears once the generated file is ready.

### Backend
The backend of our web application serves as the API layer, built using Flask, a lightweight and versatile web framework in Python. This component is responsible for handling HTTP requests from the frontend, processing these requests, interfacing with the TensorFlow Serving component for model inferences, and returning the appropriate responses.

More precisely, it runs inference on the model served through TF Serving, concatenates generated sequences to the desired length, and modulates heart rate accordingly.

The generated file is provided for download through the frontend.

### Model Serving

The app implements a robust model serving architecture utilizing TensorFlow Serving, which is specifically engineered to serve machine learning models in a production environment.

The machine learning models are stored on a persistent filesystem and are accessed by the TF-Serving container. TensorFlow Serving is configured via a models.config file, which specifies the names and filesystem paths of the models to be served. The configuration allows TensorFlow Serving to automatically detect and serve multiple models, handling requests for different models and model versions.

Upon receiving an inference request, the Backend Service sends a RESTful API call to the TF-Serving service. The request includes the model name and the input data for inference. TensorFlow Serving processes the request, performing the inference using the specified model, and returns the prediction results to the Backend Service, which then relays them to the client.

The architecture supports concurrent processing of multiple models and versions, enabling horizontal scalability and redundancy. This is crucial for high availability and to handle potential spikes in request volume.